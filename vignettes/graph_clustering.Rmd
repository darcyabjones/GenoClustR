---
title: "basic-usage"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{basic-usage}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)

options(max.print = 10000)
```

```{r setup}
#library('GenoClustR')
devtools::load_all()
library('rlang')
library('ggplot2')
library("Hmisc")
library('gplots')
library("WGCNA")
library("adjclust")
library("circlize")
library("ComplexHeatmap")
enableWGCNAThreads()
```

```{r}
plotit <- function(mat) {
  heatmap(mat, Rowv = NA, Colv = NA, symm = TRUE)
}
```

```{r}
set.seed(666)
d <- matrix(rpois(220 * 50, lambda = 0.5), nrow = 220, ncol = 50)
true_clusters <- numeric(nrow(d))

d[5:14, 1:4] <- rpois(10 * 4, lambda = 20)
true_clusters[5:14] <- 1

d[20:24, 5:8] <- rpois(5 * 4, lambda = 20) # Non-overlapping but adjacent
d[25:29, 1:4] <- rpois(5 * 4, lambda = 20)
true_clusters[20:24] <- 2
true_clusters[25:29] <- 3

d[35:40, 9:12] <- rpois(6 * 4, lambda = 20)
d[40:45, 13:16] <- rpois(6 * 4, lambda = 20)
true_clusters[35:40] <- 4
true_clusters[41:45] <- 5

d[50:60, 5:8] <- rpois(11 * 4, lambda = 20)
d[55:65, 21:24] <- rpois(11 * 4, lambda = 20)
true_clusters[50:65] <- 6

d[70:80, 25:28] <- rpois(11 * 4, lambda = 20)
d[72:82, 29:32] <- rpois(11 * 4, lambda = 20)
true_clusters[70:82] <- 7

d[85:95, 9:12] <- rpois(11 * 4, lambda = 20)
d[95:105, 13:16] <- rpois(11 * 4, lambda = 20)
true_clusters[85:105] <- 8

# Gappy
d[c(110:114, 116:120), 5:8] <- rpois(10 * 4, lambda = 20)
true_clusters[110:120] <- 9

# Gap near edge
d[c(124:131, 133:134), 25:28] <- rpois(10 * 4, lambda = 20)
true_clusters[124:134] <- 10

# 2 consecutive gaps
d[140:143, 29:32] <- rpois(4 * 4, lambda = 20)
d[146:150, 29:32] <- rpois(5 * 4, lambda = 20)
true_clusters[140:150] <- 11

# 2 gaps each end
d[155:156, 33:36] <- rpois(2 * 4, lambda = 20)
d[158:162, 33:36] <- rpois(5 * 4, lambda = 20)
d[164:165, 33:36] <- rpois(2 * 4, lambda = 20)
true_clusters[155:165] <- 12

# 3 consecutive
d[170:173, 37:40] <- rpois(4 * 4, lambda = 20)
d[177:180, 37:40] <- rpois(4 * 4, lambda = 20)
true_clusters[170:180] <- 13

# 3 consecutive bigger_cluster
d[185:190, 29:32] <- rpois(6 * 4, lambda = 20)
d[194:199, 29:32] <- rpois(6 * 4, lambda = 20)
true_clusters[185:199] <- 14

# 3 spread
d[205:215, 41:44] <- rpois(11 * 4, lambda = 20)
d[c(208, 210, 212), 41:50] <- rpois(3 * 10, lambda = 5)
true_clusters[205:215] <- 15

d <- d / colSums(d)

cor <- abs(cor(t(d), method = "pearson"))
heatmap(d, Rowv = NA, Colv = NA, scale = "none")
heatmap(cor, Rowv = NA, Colv = NA, symm = TRUE, scale = "none")
heatmap(1 * (cor >= 0.5), Rowv = NA, Colv = NA, symm = TRUE, scale = "none")
true_clusters <- true_clusters + 1
```

So how does the thresholded pipeline do?

```{r}
thresh_clust <- threshold_clustering(cor, threshold = 0.5, max_cluster = 50, edge_fill_rate = 0.6)$clusters
thresh_clust_pb <- numeric(nrow(cor))

for (i in seq_len(nrow(thresh_clust))) {
  thresh_clust_pb[thresh_clust[i, "start"]:thresh_clust[i, "end"]] <- i
}
thresh_clust_pb <- thresh_clust_pb + 1
thresh_clust
```

Pretty good actually.
The only one it didn't get right was the gappy cluster, which had the boundaries wrong.
Incidentally, this is the one that is most likely to have issues with the thresholding method.

Most of these examples are pretty easy, but they're the clear cases that any method should be able to deal with.

What if we use the WGCNA method for cleaning clusters instead?


```{r}
powers = c(c(1:10), seq(from = 12, to = 40, by=2))
sft = pickSoftThreshold(t(d), powerVector = powers, verbose = 5)

sizeGrWindow(9, 5)
par(mfrow = c(1,2))
cex1 = 0.9

# Scale-free topology fit index as a function of the soft-thresholding power
plot(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],
     xlab="Soft Threshold (power)",ylab="Scale Free Topology Model Fit,signed R^2",type="n",
     main = paste("Scale independence"));
text(sft$fitIndices[,1], -sign(sft$fitIndices[,3])*sft$fitIndices[,2],
     labels=powers,cex=cex1,col="red");
# this line corresponds to using an R^2 cut-off of h
abline(h=0.90,col="red")
# Mean connectivity as a function of the soft-thresholding power
plot(sft$fitIndices[,1], sft$fitIndices[,5],
     xlab="Soft Threshold (power)",ylab="Mean Connectivity", type="n",
     main = paste("Mean connectivity"))
text(sft$fitIndices[,1], sft$fitIndices[,5], labels=powers, cex=cex1,col="red")
```

Based on this 18 would be the right power, but i've looked at it and actually 1 is more like what I want.

```{r}
cor_adj <- adjacency(t(d), power = 3)
plotit(cor_adj)
```


```{r}
thresh_clust_tom <- threshold_clustering(cor_adj, threshold = 0.5, edge_fill_rate = 0.6, max_cluster = 50, smooth = "TOM")$clusters
thresh_clust_tom_pb <- numeric(nrow(cor))

for (i in seq_len(nrow(thresh_clust_tom))) {
  thresh_clust_tom_pb[thresh_clust_tom[i, "start"]:thresh_clust_tom[i, "end"]] <- i
}
thresh_clust_tom_pb <- thresh_clust_tom_pb + 1
thresh_clust_tom
```



So what else can we do?

```{r}
## from http://tr.im/hH5A
logsumexp <- function (x) {
  y <- max(x)
  y + log(sum(exp(x - y)))
}

softmax <- function (x) {
  exp(x - logsumexp(x))
}


unity <- function(xi, xj) {
  return(1)
}


rbf <- function(xi, xj, std = 1, power = 2) {
  ratio <- (abs(xi - xj) ** 2) / (2 * (std ** power))
  return(exp(-1 * ratio))
}

gen_pm_features <- function(mat, context = 3, dist_penalty = unity) {
  # p_rev, p_fwd, p_none
  out <- matrix(NA, nrow = nrow(mat), ncol = 4)
  for (i in seq_len(nrow(mat))) {
    fwd_ <- numeric(context)
    rev_ <- numeric(context)

    for (j in seq_len(context)) {
      if ((i + j) >  nrow(mat)) {
        f <- 0
      } else {
        f <- mat[i, (i + j)]
      }
      dp <- dist_penalty(1, j)
      
      fwd_[j] <- dp * f
      
      if ((i - j) <= 0) {
        r <- 0
      } else {
        r <- mat[i, (i - j)]
      }
      
      rev_[j] <- dp * r
    }

    fwd_ <- (fwd_ - 0.5) * 2
    rev_ <- (rev_ - 0.5) * 2

    both_ <- sum(c(fwd_, rev_), na.rm = FALSE)
    fwd2_ <- sum(c(fwd_, -1 * rev_), na.rm = FALSE)
    rev2_ <- sum(c(-1 * fwd_, rev_), na.rm = FALSE)
    neither_ <- sum(-1 * c(fwd_, rev_), na.rm = FALSE)
    
    out[i,] <- softmax(c(rev2_, fwd2_, both_, neither_))
  }
  colnames(out) <- c("rev", "fwd", "both", "neither")
  return(out)
}

#heatmap(gen_pm_features(cor, context = 4), Rowv = NA, Colv = NA)

#gen_pm_features(cor, context = 10, dist_penalty = function(xi, xj) {rbf(xi, xj, std = 2, power = 4)})
```


```{r}
transition_table <- matrix(0, nrow = 4, ncol = 4)
rownames(transition_table) <- colnames(transition_table) <- states <- c("nocluster", "cluster_start", "cluster", "cluster_end")

transition_table["cluster_end", "nocluster"] <- 0.2
transition_table["nocluster", "nocluster"] <- 0.8

transition_table["cluster_start", "cluster"] <- 0.1
transition_table["cluster", "cluster"] <- 0.9

transition_table["cluster_start", "cluster_end"] <- 0.0
transition_table["cluster", "cluster_end"] <- 1.0

transition_table["cluster_end", "cluster_start"] <- 0.1
transition_table["nocluster", "cluster_start"] <- 0.9

#heatmap(transition_table, Rowv = NA, Colv = NA, scale = "none")
transition_table <- log(transition_table)
```


```{r}
start_table = matrix(0, nrow = 1, ncol = 4)
colnames(start_table) <- c("nocluster", "cluster_start", "cluster", "cluster_end")
start_table[1, ] <- c(0.99, 0.01, 0.0, 0.0)

emission_table <- matrix(0, nrow = 4, ncol = 4)
rownames(emission_table) <- c("nocluster", "cluster_start", "cluster", "cluster_end")
colnames(emission_table) <- symbols <- c("rev", "fwd", "both", "neither")
emission_table["cluster_start",] <- c(0.225, 0.5, 0.225, 0.05)
emission_table["cluster",] <- c(0.166667, 0.166667, 0.5, 0.166667)
emission_table["cluster_end",] <- c(0.5, 0.225, 0.225, 0.05)
emission_table["nocluster",] <- c(0.1, 0.1, 0.1, 0.7)
#heatmap(emission_table, Rowv = NA, Colv = NA)

start_table <- log(start_table)
emission_table <- log(emission_table)
```


```{r}
obs_pm <- gen_pm_features(cor, context = 4)
obs <- colnames(obs_pm)[apply(obs_pm, MARGIN = 1, FUN = which.max)]
```


```{r}
trellis <- matrix(0, nrow = length(states), ncol = length(obs))
rownames(trellis) <- states

pointers <- matrix(0, nrow = length(states), ncol = length(obs))
rownames(pointers) <- states
```


```{r}
weighted_obs <- function(obs, emission_table) {
  multiplied <- t(t(emission_table) + obs)
  
  # Taking exp is important because we're in log space
  weighted_score <- rowSums(exp(multiplied))
  
  # Convert back to log for stability
  return(log(weighted_score))
}

weighted_obs(log(obs_pm[1,]), emission_table)
```


```{r}
# initial state
emissions <- apply(
  log(obs_pm),
  MARGIN = 1,
  FUN = function(x) {weighted_obs(x, emission_table)}
)

#emissions <- emission_table[, obs]
emission_preds <- rownames(emissions)[apply(emissions, MARGIN = 2, FUN = which.max)]

trellis[, 1] <- t(start_table + emissions[, 1])

for (o in seq_len(ncol(trellis) - 1)) {
  o <- o + 1
  for (state in states) {
    k <- trellis[, o - 1] + transition_table[, state] + emissions[state, o]
    top <- names(which.max(k))
    trellis[state, o] <- k[top]
    pointers[state, o] <- top
  }
}
```


```{r}
best_state <- names(which.max(trellis[, ncol(trellis)]))
best_path <- character(ncol(trellis))

for (i in rev(seq_len(ncol(trellis)))) {
  best_path[i] <- best_state
  best_state <- pointers[best_state, i]
}
```


```{r}
min_cluster <- 4
ranges <- list()

h <- 1
last_start <- NULL
for (i in seq_along(best_path)) {
  state <- best_path[i]
  if (state == "cluster_start") {
    if (!is.null(last_start)) {
      stop("this shouldn't happen")
    }
    last_start <- i
  } else if (state == "cluster_end") {
    if (is.null(last_start)) {
      stop("this shouldn't happen")
    }
    
    if ((abs(last_start - i) + 1) >= min_cluster) {
      ranges[[h]] <- c("start" = last_start, "end" = i)
      h <- h + 1
    }
    last_start <- NULL
  } else if (!state %in% c("cluster", "nocluster")) {
    stop("This shouldn't happen")
  }
}

state_machine_hmm_ranges <- do.call(rbind, ranges)
state_machine_hmm_ranges


state_machine_hmm_pb <- numeric(nrow(cor))

for (i in seq_len(nrow(state_machine_hmm_ranges))) {
  state_machine_hmm_pb[state_machine_hmm_ranges[i, 1]:state_machine_hmm_ranges[i, 2]] <- i
}

state_machine_hmm_pb <- state_machine_hmm_pb + 1
```


Heres the function for calculating the directionality index.
I found that it didn't really work to construct states for the HMM, but might be ok for a traditional segmentation algorithm.

```{r}
directionality_index <- function(mat, context = 10, eps = .Machine$double.eps) {
  out <- numeric(nrow(mat)) # matrix(NA, nrow = nrow(mat), ncol = 3)
  
  for (i in seq_len(nrow(mat))) {
    fwd_ <- numeric(context)
    rev_ <- numeric(context)
    
    for (j in seq_len(context)) {
      if ((i + j) >  nrow(mat)) {
        f <- 0
      } else {
        f <- mat[i, (i + j)]
      }
      
      fwd_[j] <- f
      
      if ((i - j) <= 0) {
        r <- 0
      } else {
        r <- mat[i, (i - j)]
      }
      
      rev_[j] <- r
    }
    
    r <- rev_
    f <- fwd_
    
    rev_ = sum(rev_)
    fwd_ = sum(fwd_)
    expected <- (fwd_ + rev_) / 2
    
    if (rev_ == fwd_) {
      one <- 0
    } else {
      one <- (rev_ - fwd_) / abs(rev_ - fwd_)
    }
    two <- (
      (((fwd_ - expected) ** 2) / expected) +
      (((rev_ - expected) ** 2) / expected)
    )

    DI <- one * two
    
    if (is.na(DI)) {
      print(f)
      print(r)
      print(rev_)
      print(fwd_)
      print(expected)
      print(one)
      print(two)
      print("")
      
    }
    
    out[i] <- DI
  }
  return(out)
}


plot(directionality_index(cor, context = 50))
di <- directionality_index(cor, context = 50)
```


Constrained hierarchical clustering


```{r}
cor_dis <- 1 - cor
ac <- adjClust(cor_dis, type="dissimilarity")
plot(ac)
```


```{r}
library(cluster)


k_range <- 10:50
sl_scores <- numeric(length(k_range))
sl_ks <- list()
for (k in k_range) {
  adjclust_pb_init <- unname(cutree_chac(ac, h = 1.0, k = k)) + 1
  sl <- silhouette(adjclust_pb_init, dmatrix = cor_dis)
  mask <- which(vapply(split(sl[, "sil_width"], sl[, "cluster"]), FUN = mean, FUN.VALUE = 0.0) < 0)

  adjclust_pb_init[adjclust_pb_init %in% mask] <- 1
  sl <- silhouette(adjclust_pb_init, dmatrix = cor_dis)
  sl_mean <- mean(sl[, "sil_width"], na.rm = TRUE)
  sl_scores[k] <- sl_mean
  sl_ks[[k]] <- sl
}

print(which.max(sl_scores))
plot(sl_scores)
plot(sl_ks[[which.max(sl_scores)]])
```

```{r}
k <- 40 #which.max(sl_scores)
plot(sl_ks[[k]])

adjclust_pb_init <- unname(cutree_chac(ac, h = 1.0, k = k)) + 1
cluster_means <- numeric(length(unique(adjclust_pb_init)))
for (i in unique(adjclust_pb_init)) {
  mask <- adjclust_pb_init == i
  sub_mat <- ac$data[mask, mask]
  m <- mean(sub_mat[upper.tri(sub_mat)], na.rm = TRUE)
  cluster_means[i] <- m
}

hist(cluster_means, breaks = 50)
```


```{r}
cutoff <- 0.8
sl <- sl_ks[[which.max(sl_scores)]]
mask <- unname(which(vapply(split(sl[, "sil_width"], sl[, "cluster"]), FUN = mean, FUN.VALUE = 0.0) < 0))

cluster_map <- numeric(length(unique(adjclust_pb_init)))

h <- 2
for (i in seq_along(cluster_means)) {
  if (is.na(cluster_means[i])) {
    cluster_map[i] <- i
    next
  }
  if (cluster_means[i] < cutoff) {
    cluster_map[i] <- 1
  } else {
    cluster_map[i] <- h
    h <- h + 1
  }
}

adjclust_pb <- cluster_map[adjclust_pb_init]

sl <- silhouette(adjclust_pb, dmatrix = cor_dis)
cbind(true_clusters, adjclust_pb)
```


```{r}
adjacency <- adjacency(t(d), power = 18)
TOM <- TOMsimilarity(adjacency)
dissTOM <- 1 - TOM
heatmap(adjacency, Rowv = NA, Colv = NA)
heatmap(TOM, Rowv = NA, Colv = NA)
```

```{r}
geneTree <- hclust(as.dist(dissTOM), method = "average")
plot(geneTree)
```

```{r}
minModuleSize <- 4
dynamicMods <- cutreeDynamic(
  dendro = geneTree,
  distM = dissTOM,
  deepSplit = 4,
  pamRespectsDendro = FALSE,
  minClusterSize = minModuleSize
)

table(dynamicMods)
```

```{r}
wgcna_clusters <- unname(dynamicMods)
wgcna_clusters <- wgcna_clusters + (1 - min(wgcna_clusters))
cluster_means <- numeric(length(unique(wgcna_clusters)))
for (i in unique(wgcna_clusters)) {
  mask <- wgcna_clusters == i
  sub_mat <- ac$data[mask, mask]
  m <- mean(sub_mat[upper.tri(sub_mat)], na.rm = TRUE)
  cluster_means[i] <- m
}

hist(cluster_means, breaks = 50)
```


```{r}
# orders the cluster numbers sequentially
fix_cluster_order <- function(path) {
  h <- 2
  name_map <- numeric(length(unique(path)))
  name_map[1] <- 1
  for (i in seq_along(path)) {
    val <- path[i]
    if (is.na(name_map[val]) || (name_map[val] == 0)) {
      name_map[val] <- h
      h <- h + 1
    }
  }
  
  return(name_map[unname(path)])
}
```


```{r}
threshold <- 0.8
cluster_map <- numeric(length(unique(wgcna_clusters)))

h <- 2
for (i in seq_along(cluster_means)) {
  if (is.na(cluster_means[i])) {
    cluster_map[i] <- 1
    next
  }
  if (cluster_means[i] < threshold) {
    cluster_map[i] <- 1
  } else {
    cluster_map[i] <- h
    h <- h + 1
  }
}

wgcna_clusters_pb <- fix_cluster_order(cluster_map[wgcna_clusters])
wgcna_clusters_pb
```

```{r}
MElist <- moduleEigengenes(t(d), colors = wgcna_clusters_pb)
MEs <- MElist$eigengenes
MEDiss <- 1 - cor(MEs)
heatmap(MEDiss, Rowv = NA, Colv = NA, symm = TRUE, scale = "none")
```


```{r}
MEs <- as.matrix(MEs)
MEdists <- t(MEs) %*% MEs
MEsmdists <- t(apply(MEdists, MARGIN = 1, FUN = softmax))
heatmap(MEsmdists, Rowv = NA, Colv = NA, symm = TRUE, scale = "none")
```

```{r}
TOM2 <- TOM
TOM2[lower.tri(TOM2)] <- NA

dynamic_mods <- unname(wgcna_clusters_pb)
nclusters <- max(dynamic_mods)
emission_matrix <- matrix(0, nrow = nclusters, ncol = nclusters)

for (cluster in seq_len(nclusters)) {
  mask <- dynamic_mods == cluster
  
  sum_total_weights <- sum(TOM2[mask, ], na.rm = TRUE) + 1
  
  for (cluster2 in seq_len(nclusters)) {
    mask2 <- dynamic_mods == cluster2
    sum_weights <- sum(TOM2[mask, mask2], na.rm = TRUE) + 1
    emission_matrix[cluster, cluster2] <- sum_weights / sum_total_weights
  }
}

emission_matrix <- apply(log(emission_matrix), MARGIN = 2, FUN = softmax)

heatmap(emission_matrix, Rowv = NA, Colv = NA, symm = TRUE, scale = "none")
```


```{r}
m <- matrix(0, ncol = ncol(TOM2), nrow = max(wgcna_clusters_pb))

m[matrix(c(wgcna_clusters_pb, seq_len(ncol(TOM2))), ncol = 2, nrow = ncol(TOM2))] <- 1
heatmap(m, Colv = NA)
```

```{r}
start_probabilities <- table(wgcna_clusters_pb) / length(wgcna_clusters_pb)
start_probabilities
```



```{r}
states <- unname(wgcna_clusters_pb)
wgcna_clusters_pb <- fix_cluster_order(states)
states
```


```{r}
library(HMM)

transition_matrix2 <- matrix(1, nrow = nrow(emission_matrix), ncol = ncol(emission_matrix))
diag_weight <- 5
null_weight <- 1
switch_weight <- 0.5

transition_matrix2[1, ] <- null_weight
transition_matrix2[, 1] <- null_weight
diag(transition_matrix2) <- diag_weight
transition_matrix2 <- apply(transition_matrix2, MARGIN = 1, FUN = softmax)

hmm <- initHMM(
  States = seq_along(unique(states)),
  Symbols = seq_along(unique(states)),
  startProbs = unname(start_probabilities),
  transProbs = transition_matrix2,
  emissionProbs = emission_matrix
)
wgcna_clusters_smoothed_pb <- fix_cluster_order(viterbi(hmm, states))

results <- cbind(true_clusters, thresh_clust_pb, thresh_clust_tom_pb, state_machine_hmm_pb, wgcna_clusters_pb, wgcna_clusters_smoothed_pb, adjclust_pb)
results
```

```{r}
results2 <- results
results2[results2 == 1] <- NA
heatmap(t(results2), Rowv = NA, Colv = NA, scale = "none")
```


```{r}
find_ranges_from_pb <- function(path, excl_cluster = 1, min_cluster = 4) {
  ranges <- list()
  
  h <- 1
  last_start <- NULL
  last_state <- NULL
  for (i in seq_along(path)) {
    state <- path[i]
    if (i == 1) {
      last_start <- i
      last_state <- state
    }
    
    if (state != last_state) {
      end <- i
      cluster_length <- end - last_start
      if ((cluster_length >= min_cluster) && (last_state != 1)) {
        ranges[[h]] <- c("start" = last_start, "end" = i - 1)
        h <- h + 1
      }
      
      last_start <- i
      last_state <- state
      
    }
  }
  
  ranges <- do.call(rbind, ranges)
  ranges
}
```


```{r}
ranges <- find_ranges_from_pb(adjclust_pb)

for (i in seq_len(nrow(ranges))) {
  context <- 5
  start <- max(c(ranges[i, "start"] - context, 1))
  end <- min(c(ranges[i, "end"] + context, nrow(cor)))

  heatmap(cor[start:end, start:end], Rowv = NA, Colv = NA, symm = TRUE)
}
```


```{r, fig.width=8, fig.height=10}
library(circlize)
r <- results
colnames(r) <- c('clusters', 'threshold', 'threshold_tom', 'state_machine', 'wgcna', 'wgcna_smoothed', 'adjclust')
r[r == 1] <- NA
#r <- as.data.frame(t(apply(r, MARGIN = 1, FUN = as.factor)))
r <- as.data.frame(r)
pal <- rainbow(max(r, na.rm = TRUE))
names(pal) <- seq_along(pal)
colours <- lapply(colnames(r), FUN=function(x) {pal})
names(colours) <- colnames(r)
#names(colours) <- 1:length(colours)

ha <- columnAnnotation(
  df = r,
  name = "clusters",
  col = colours,
  show_legend = FALSE,
  na_col = "#E0DFDE",
  annotation_name_side = "left"
)

colours2 <- colorRamp2(
  seq(-1, 1, length.out = 29),
  rev(paletteer::paletteer_c("ggthemes::Red-Blue-White Diverging", 29))
)
cor2 <- cor
cor2[upper.tri(cor)] <- NA

h <- Heatmap(
  cor2,
  col = rev(paletteer::paletteer_c("ggthemes::Red-Blue-White Diverging", 30)),
  cluster_rows = FALSE,
  cluster_columns = FALSE,
  show_heatmap_legend = FALSE,
  bottom_annotation = ha,
  width = unit(6, "in"),
  height = unit(6, "in"),
  na_col = "white",
  row_names_side = "left"
)

png("synthetic_clusters.png", width = 8, height = 10, units = "in", res = 450)
print(h)
dev.off()

print(h)
```



